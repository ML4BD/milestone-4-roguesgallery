{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1722e6-bee1-4895-8781-95b36ce08c00",
   "metadata": {},
   "source": [
    "# Regularity Feature Generation for A1 and A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b095352-8b59-4f94-a176-e1afbeb77f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import timedelta, datetime \n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da52a08c-b607-4705-a37d-99cd746b6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '...' # You many change the directory\n",
    "\n",
    "#import datasets, the form of the dataframe necessary is described in our report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26390ccf-be8c-494f-807a-a83d61b3691b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16496fa1-423f-4dd0-9dbd-d126c86a3ab4",
   "metadata": {},
   "source": [
    "# A1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c6f6f-739c-4923-9030-4c2f54bb69ac",
   "metadata": {},
   "source": [
    "Below we define all necessary functions to generate the regularity features for our lernnavi data as described in the paper: \"How to Quantify Student Regularity?\" from the ML4ED lab. They were taken varbatim from the corresponding github repository, with minor adjustments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666d2d3-1741-41c6-b1f1-eb68dab07876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_days(wi, wj):\n",
    "    m1, m2 = np.where(wi == 1)[0], np.where(wj == 1)[0]\n",
    "    if len(m1) == 0 or len(m2) == 0:\n",
    "        return 0\n",
    "    return len(np.intersect1d(m1, m2)) / max(len(m1), len(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49967523-98a3-4d07-bb72-957a7334a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_divergence(p1, p2, a1, a2):\n",
    "    a = p1 - p2\n",
    "    b = p1 + p2\n",
    "    frac = np.divide(a, b, out=np.zeros(a.shape, dtype=float), where=b != 0)\n",
    "    m1 = np.where(a1 > 0)[0]\n",
    "    m2 = np.where(a2 > 0)[0]\n",
    "    union = set(m1) & set(m2)\n",
    "    if len(union) == 0: return np.nan\n",
    "    return 1 - (1 / len(union)) * np.sum(np.square(frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b59ce2-c86b-493f-9f44-a67e6a458ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_measures(data, mode, weeks):\n",
    "    \"\"\"\n",
    "    Return the PDH and PWD measures up to a given week, weeks\n",
    "    \"\"\"\n",
    "    \n",
    "    data = data[data['week'] < weeks]\n",
    "    if mode == 'dayhour': #PDH\n",
    "        hours = data['date'].dt.hour.astype(int).to_list()\n",
    "        activity = np.array([hours.count(h) for h in np.arange(24)])\n",
    "        if np.sum(activity) == 0:\n",
    "            print(\"Feature is invalid: the dayhour mode is invalid. Returning nan.\")\n",
    "            return np.nan\n",
    "        entropy = stats.entropy(activity / np.sum(activity))\n",
    "        return (np.log(24) - entropy) * np.max(activity)\n",
    "    elif mode == 'weekday': #PWD\n",
    "        weekdays = data['date'].dt.weekday.astype(int).to_list()\n",
    "        activity = np.array([weekdays.count(h) for h in np.arange(7)])\n",
    "        if np.sum(activity) == 0:\n",
    "            print(\"Feature is invalid: the weekday mode is invalid. Returning nan.\")\n",
    "            return np.nan\n",
    "        entropy = stats.entropy(activity / np.sum(activity))\n",
    "        return (np.log(7) - entropy) * np.max(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e2753-6e53-449e-9d82-a5c918c0aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary to accurately calculate the week of a year given a timestamp\n",
    "def create_week_number(d):\n",
    "    return (d.isocalendar()[0] - 2021) * 53 + d.isocalendar()[1] - 1\n",
    "# https://stackoverflow.com/questions/59425176/how-to-continue-the-week-number-when-the-year-changes-using-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28a58b-37e4-4784-8738-e331b9aa5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_similarity(data, mode, weeks):\n",
    "    \"\"\"\n",
    "    Return the WS1, WS2 and WS3 measures up to a given week, weeks\n",
    "    \"\"\"\n",
    "    \n",
    "    data['weekday'] = data['date'].dt.weekday.astype(int)\n",
    "    data = data[data['week'] < weeks]\n",
    "    \n",
    "    workload = np.zeros((weeks, 7))\n",
    "    workload[data['week'], data['weekday']] += 1\n",
    "    hist = workload / np.sum(workload)\n",
    "\n",
    "    # Hours of activity starting at midnight of the first timestamp\n",
    "    hours = (data['date']).values.astype(np.int64) // 10 ** 9 // 3600\n",
    "    min_day = data.date.min() # First day of activity\n",
    "    # Make the hours start from midnight of the first day\n",
    "    hours -= int(datetime(min_day.year, min_day.month, min_day.day).timestamp() / 3600)\n",
    "\n",
    "    period_length = weeks * 7 * 24\n",
    "    activity = np.array([int(t in hours) for t in range(period_length)]).reshape((weeks, 7 * 24))\n",
    "    activity = np.array([week.reshape((7, 24)).sum(axis=1) for week in activity])  # shape (weeks, 7)\n",
    "    if mode == 'm1': #WS1\n",
    "        return np.mean([similarity_days(workload[i], workload[j]) for i in range(workload.shape[0]) for j in range(i+1, workload.shape[0])])\n",
    "    elif mode == 'm2': #WS2\n",
    "        res = []\n",
    "        for i in range(activity.shape[0]):\n",
    "            for j in range(i + 1, activity.shape[0]):\n",
    "                if not activity[i].any() or not activity[j].any():\n",
    "                    continue\n",
    "                res.append(1 - jensenshannon(activity[i], activity[j], 2.0))\n",
    "        if len(res) == 0:\n",
    "            #print(\"Feature is invalid. Will return nan\")\n",
    "            return np.nan\n",
    "        return np.mean(np.clip(np.nan_to_num(res), 0, 1))\n",
    "    elif mode == 'm3': #WS3\n",
    "        res = []\n",
    "        for i in range(activity.shape[0]):\n",
    "            for j in range(i + 1, activity.shape[0]):\n",
    "                if not activity[i].any() or not activity[j].any():\n",
    "                    continue\n",
    "                res.append(chi2_divergence(activity[i], activity[j], hist[i], hist[j]))\n",
    "        if len(res) == 0:\n",
    "            return np.nan\n",
    "        return np.mean(np.nan_to_num(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61fcc15-b492-44e9-8993-ee2e279e7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_transform(Xi, f, n):\n",
    "    return np.dot(np.exp(-2j * np.pi * f * n), Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bbdc2b-adf0-4480-8ea8-fb7de76da668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(data, mode, weeks):\n",
    "    \"\"\"\n",
    "    Return the FDH, FWD, and FWH measures up to a given week, weeks \n",
    "    \"\"\"\n",
    "    \n",
    "    if mode == 'm1': #FDH\n",
    "        # Convert date to hours starting from 0\n",
    "        hours = data['date'].values.astype(np.int64) // 10 ** 9 // 3600\n",
    "        hours -= min(hours)\n",
    "        period_length = weeks * 7 * 24\n",
    "        activity = np.array([int(t in hours) for t in range(period_length)])  # 1 if active at hour t 0 o.w.\n",
    "        if np.sum(activity) == 0:\n",
    "            #logging.debug('feature {} is invalid: the m1 mode is invalid'.format(self.name))\n",
    "            return np.nan #Feature.INVALID_VALUE\n",
    "        n = np.arange(period_length)\n",
    "        return abs(fourier_transform(activity, 1 / 24, n))\n",
    "\n",
    "    elif mode == 'm2': #FWH\n",
    "        period_length = weeks * 7 * 24\n",
    "        hours = data['date'].values.astype(np.int64) // 10 ** 9 // 3600\n",
    "        hours -= min(hours)\n",
    "        activity = np.array([int(t in hours) for t in range(period_length)])\n",
    "        n = np.arange(period_length)\n",
    "        return abs(fourier_transform(activity.flatten(), 1 / (7 * 24), n))\n",
    "\n",
    "    elif mode == 'm3': #FWD\n",
    "        # Convert date to days starting from 0\n",
    "        days = data['date'].values.astype(np.int64) // 10 ** 9 // (24 * 3600)\n",
    "        days -= min(days)\n",
    "        period_length = weeks * 7\n",
    "        activity = np.array([int(d in days) for d in range(period_length)])  # 1 if active at day d 0 o.w.\n",
    "        n = np.arange(period_length)\n",
    "        return abs(fourier_transform(activity, 1 / 7, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6841576-6ae5-4e47-9a70-9d5f98404306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_agg_regularity(data, weeks):\n",
    "    \"\"\"\n",
    "    Return regularity measures for activity aggregated over a predefined number of weeks\n",
    "    \"\"\"\n",
    "    \n",
    "    #time based measures\n",
    "    PDH = data.groupby('user_id').apply(lambda x: time_measures(x, 'dayhour', weeks)).reset_index()\n",
    "    PWD = data.groupby('user_id').apply(lambda x: time_measures(x, 'weekday', weeks)).reset_index(drop=True)\n",
    "    \n",
    "    #profile similarity \n",
    "    WS1 = data.groupby('user_id').apply(lambda x: profile_similarity(x, 'm1', weeks)).reset_index(drop=True)\n",
    "    WS2 = data.groupby('user_id').apply(lambda x: profile_similarity(x, 'm2', weeks)).reset_index(drop=True)\n",
    "    WS3 = data.groupby('user_id').apply(lambda x: profile_similarity(x, 'm3', weeks)).reset_index(drop=True)\n",
    "    \n",
    "    #frequency based measures\n",
    "    FDH = data.groupby('user_id').apply(lambda x: freq(x, 'm1', weeks)).reset_index(drop=True)\n",
    "    FWH = data.groupby('user_id').apply(lambda x: freq(x, 'm2', weeks)).reset_index(drop=True)\n",
    "    FWD = data.groupby('user_id').apply(lambda x: freq(x, 'm3', weeks)).reset_index(drop=True)\n",
    "    \n",
    "    reg_features = pd.concat([PDH,PWD,WS1,WS2,WS3,FDH,FWH,FWD], axis=1, ignore_index=False)\n",
    "    \n",
    "    return reg_features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acfe4ec-e059-4f6b-8727-4ec7a8fd60c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc131c5c-9e0a-4a7f-8cdf-26415a5dde7c",
   "metadata": {},
   "source": [
    "## A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de796b-b507-4fca-a076-f82351eb8169",
   "metadata": {},
   "source": [
    "Below we define the function necessary to compute the behavioural features used in approach A2, as described in our report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d7afdbb-d885-4770-8891-37d709a912e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def behavioural_features(df, lvl_chks):\n",
    "    \"\"\"\n",
    "    Compute features to feed decision tree classifier for level check scores.\n",
    "    \n",
    "    Input: df - complete DataFrame with user activity data as described in report section 3\n",
    "           lvl_chks - DataFrame where first column is user_id and second is week on which user_id does a level check\n",
    "    Output: behavioural as described above features for each row of lvl_chks\n",
    "    \"\"\"\n",
    "    \n",
    "    users = list(set(lvl_chks.user_id))\n",
    "    behavioural_features = pd.DataFrame(columns = ['num_actions_per_week',\n",
    "                                                   'eng_score',\n",
    "                                                   'FDH',\n",
    "                                                   'FWH',\n",
    "                                                   'FWD',\n",
    "                                                   'num_weeks_on'],\n",
    "                                        index = [lvl_chks['user_id'], lvl_chks['week']]) #same nrows lvl_chks\n",
    "    \n",
    "    behavioural_features_dicts = []\n",
    "    \n",
    "    for user in users:\n",
    "        lvl_chk_weeks = lvl_chks[lvl_chks['user_id'] == user].week.tolist()\n",
    "        \n",
    "        for j, week in enumerate(lvl_chk_weeks): \n",
    "            df_user_week = df[(df['user_id'] == user) & (df['week'] <= week)]\n",
    "            \n",
    "            if df_user_week.empty:\n",
    "                behavioural_features_dicts.append({'num_actions_per_week' : 0,\n",
    "                                                   'eng_score' : 0,\n",
    "                                                   'FDH' : 0,\n",
    "                                                   'FWH' : 0,\n",
    "                                                   'FWD' : 0,\n",
    "                                                   'num_weeks_on' : 0,\n",
    "                                                   'user_id' : user,\n",
    "                                                   'week' : week,\n",
    "                                                   'validated' : lvl_chks[(lvl_chks['user_id'] == user) &\n",
    "                                                                          (lvl_chks['week'] == week)]['validated'].values[0]})\n",
    "                                                \n",
    "                continue \n",
    "            \n",
    "            sum_actions_week = df_user_week['action'].count() \n",
    "            sum_eng_actions_week = df_user_week[(df_user_week['action'] == 'SUBMIT_ANSWER') |\n",
    "                                                (df_user_week['action'] == 'GO_TO_THEORY')]['action'].count()\n",
    "            num_actions_per_week = sum_actions_week / (j+1)\n",
    "            eng_prop = sum_eng_actions_week / sum_actions_week\n",
    "            eng_score = 1 if eng_prop >= 0.25 else 0 \n",
    "            \n",
    "            FDH = freq(df_user_week, 'm1', j+1) \n",
    "            FWH = freq(df_user_week, 'm2', j+1)\n",
    "            FWD = freq(df_user_week, 'm3', j+1)\n",
    "            \n",
    "            num_weeks_on = j+1 #(i+1) counts how many weeks for which we have observed the user use the platform\n",
    "            \n",
    "            behavioural_features_dicts.append({'num_actions_per_week' :num_actions_per_week,\n",
    "                                               'eng_score' : eng_score,\n",
    "                                               'FDH' : FDH,\n",
    "                                               'FWH' : FWH,\n",
    "                                               'FWD' : FWD,\n",
    "                                               'num_weeks_on' : num_weeks_on,\n",
    "                                               'user_id' : user,\n",
    "                                               'week' : week,\n",
    "                                               'validated' : lvl_chks[(lvl_chks['user_id'] == user) &\n",
    "                                                                      (lvl_chks['week'] == week)]['validated'].values[0]})\n",
    "            \n",
    "    behavioural_features = pd.DataFrame(behavioural_features_dicts)\n",
    "    #print(behavioural_features)\n",
    "        \n",
    "    return behavioural_features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf07319-7189-4cfc-a03c-54dc934063a0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3affcc0-56cd-48dd-9cc9-112bb8052643",
   "metadata": {},
   "source": [
    "# Appendix: Producing PWD/PWH/PDH plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6e8296-423e-4420-9a8c-47c6ace4638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_measures_plot_student(student, data, mode, weeks):\n",
    "    \"\"\"\n",
    "    Produce plots consistent with PDH and PWD measures as described in paper from ML4ED lab. \n",
    "    \n",
    "    Input: student - user_id of a given user\n",
    "           data - complete, clean dataframe of all user activity data\n",
    "           mode - identifier of PDH or PWD\n",
    "           weeks - number of weeks over which the compute the features\n",
    "    \n",
    "    Output: corresponding plots\n",
    "    \"\"\"\n",
    "    data = data[data['user_id'] == student]\n",
    "    data = data[data['week'] < weeks]\n",
    "    if mode == 'dayhour':\n",
    "        hours = data['date'].dt.hour.astype(int).to_list()\n",
    "        activity = np.array([hours.count(h) for h in np.arange(24)])\n",
    "        time_measure_data = pd.DataFrame({'hour' : np.arange(24), 'count' : activity})\n",
    "        \n",
    "        ax = time_measure_data.plot.bar(x='hour', y='count', color=greyscale[1])\n",
    "        ax.set_xticklabels(['0','1','2','3','4','5','6'],rotation=0)\n",
    "        ax.set_xlabel(\"Hour of day\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(\"Hours of activity for user {}\".format(int(student)))\n",
    "        \n",
    "        ax.get_legend().remove()\n",
    "        ax.get_figure().savefig(FIG_DIR + 'PDHex.jpg')\n",
    "\n",
    "    elif mode == 'weekday':\n",
    "        weekdays = data['date'].dt.weekday.astype(int).to_list()\n",
    "        activity = np.array([weekdays.count(h) for h in np.arange(7)])\n",
    "        time_measure_data = pd.DataFrame({'weekday' : np.arange(7), 'count' : activity})\n",
    "        \n",
    "        ax = time_measure_data.plot.bar(x='weekday', y='count', color=greyscale[1])\n",
    "        ax.set_xticklabels(['0','1','2','3','4','5','6'],rotation=0)\n",
    "        ax.set_xlabel(\"Day of week\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(\"Days of activity for user {}\".format(int(student)))\n",
    "        \n",
    "        ax.get_legend().remove()\n",
    "        ax.get_figure().savefig(FIG_DIR + 'PWHex.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ffc6d-abe1-4182-a8f2-1c86bcad8294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
